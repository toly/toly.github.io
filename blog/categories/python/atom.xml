<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Toly blog]]></title>
  <link href="http://toly.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://toly.github.io/"/>
  <updated>2014-02-14T13:10:45+04:00</updated>
  <id>http://toly.github.io/</id>
  <author>
    <name><![CDATA[Toly]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Многопоточность в одну строку]]></title>
    <link href="http://toly.github.io/blog/2014/02/13/parallelism-in-one-line/"/>
    <updated>2014-02-13T13:53:13+04:00</updated>
    <id>http://toly.github.io/blog/2014/02/13/parallelism-in-one-line</id>
    <content type="html"><![CDATA[<blockquote><p>Перевод статьи Криса Кила <a href="https://medium.com/p/40e9b2b36148">Parallelism in one line</a></p></blockquote>

<p>Python имеет ужасную репутацию, когда речь идет о возможности параллельных вычислений. Не обращая внимания на типичные рассуждения о его потоках и GIL (который обычно нормально работает), по-моему реальная проблема многопоточности Python не техническая, а педагогическая. Распространенные руководства о библиотеках <strong>threading</strong> и <strong>multiprocessing</strong> в целом неплохие, но тяжеловаты для понимания. Они начинаются с глубоких вещей, и заканчиваются до просто применяемых практик.</p>

<!-- more -->


<h2>Традиционный пример</h2>

<p>Беглое ознакомление с первыми результатами поискового запроса на тему &ldquo;Python threading tutorial&rdquo; показывает, что почти каждый из них основан на  использовании какого-либо вспомогательного класса в связке с модулем <strong>Queue</strong>.</p>

<p>Типичный пример многопоточности вида поставщик-потребитель:</p>

<p>``` python</p>

<h1>Example.py</h1>

<p>&lsquo;&rsquo;&lsquo;
Standard Producer/Consumer Threading Pattern
&rsquo;&lsquo;&rsquo;</p>

<p>import time
import threading
import Queue</p>

<p>class Consumer(threading.Thread):</p>

<pre><code>def __init__(self, queue): 
    threading.Thread.__init__(self)
    self._queue = queue 

def run(self):
    while True: 
        # queue.get() blocks the current thread until 
        # an item is retrieved. 
        msg = self._queue.get() 
        # Checks if the current message is 
        # the "Poison Pill"
        if isinstance(msg, str) and msg == 'quit':
            # if so, exists the loop
            break
        # "Processes" (or in our case, prints) the queue item   
        print "I'm a thread, and I received %s!!" % msg
    # Always be friendly! 
    print 'Bye byes!'
</code></pre>

<p>def Producer():</p>

<pre><code># Queue is used to share items between
# the threads.
queue = Queue.Queue()

# Create an instance of the worker
worker = Consumer(queue)
# start calls the internal run() method to 
# kick off the thread
worker.start() 

# variable to keep track of when we started
start_time = time.time() 
# While under 5 seconds.. 
while time.time() - start_time &lt; 5: 
    # "Produce" a piece of work and stick it in 
    # the queue for the Consumer to process
    queue.put('something at %s' % time.time())
    # Sleep a bit just to avoid an absurd number of messages
    time.sleep(1)

# This the "poison pill" method of killing a thread. 
queue.put('quit')
# wait for the thread to close down
worker.join()
</code></pre>

<p>if <strong>name</strong> == &lsquo;<strong>main</strong>&rsquo;:</p>

<pre><code>Producer()
</code></pre>

<p>```</p>

<p>Мда&hellip; Просматриваются Java'вские корни.</p>

<p>Что ж, я не хочу, что бы у вас создалось впечатление, будто схема поставщик-потребитель плоха для многопоточной разработки &ndash; это определенно не так. На самом деле такой способ хорошо подходит для решения множества задач. Однако, я думаю, что это не подходит для ежедневного применения.</p>

<h2>Проблемы (на мой взгляд)</h2>

<p>Во-первых, вам нужен шаблонный класс, который делает то, что нужно. Во-вторых, вам нужно организовать очередь, согласно которой будут обрабатываться объекты; и наконец, вам нужны методы для входа в очередь и выхода из очереди что бы делать реальную работу (скорее всего, с участием другой очереди, если вы хотите получать обратную связь или сохранять результаты работы).</p>

<h3>Больше воркеров, больше задач</h3>

<p>Следующее, что вы вероятно сделаете, это пулл воркеров, что бы выжать из Python больше производительности. Ниже приводится измененный код примера из превосходного <a href="http://www.ibm.com/developerworks/aix/library/au-threadingpython/">руководства</a> по многопоточности от IBM. Это достаточно распространенный сценарий, когда вы распределяете задачи получения веб-страниц на несколько потоков.</p>

<p>``` python</p>

<h1>Example2.py</h1>

<p>&lsquo;&rsquo;&lsquo;
A more realistic thread pool example
&rsquo;&lsquo;&rsquo;</p>

<p>import time
import threading
import Queue
import urllib2</p>

<p>class Consumer(threading.Thread):</p>

<pre><code>def __init__(self, queue): 
    threading.Thread.__init__(self)
    self._queue = queue 

def run(self):
    while True: 
        content = self._queue.get() 
        if isinstance(content, str) and content == 'quit':
            break
        response = urllib2.urlopen(content)
    print 'Bye byes!'
</code></pre>

<p>def Producer():</p>

<pre><code>urls = [
    'http://www.python.org', 'http://www.yahoo.com'
    'http://www.scala.org', 'http://www.google.com'
    # etc.. 
]
queue = Queue.Queue()
worker_threads = build_worker_pool(queue, 4)
start_time = time.time()

# Add the urls to process
for url in urls: 
    queue.put(url)  
# Add the poison pillv
for worker in worker_threads:
    queue.put('quit')
for worker in worker_threads:
    worker.join()

print 'Done! Time taken: {}'.format(time.time() - start_time)
</code></pre>

<p>def build_worker_pool(queue, size):</p>

<pre><code>workers = []
for _ in range(size):
    worker = Consumer(queue)
    worker.start() 
    workers.append(worker)
return workers
</code></pre>

<p>if <strong>name</strong> == &lsquo;<strong>main</strong>&rsquo;:</p>

<pre><code>Producer()
</code></pre>

<p>```</p>

<p>Работает отлично, но посмотрите на весь этот код! Здесь методы инициализации, списки потоков для отслеживания работы, и что хуже всего, если вы склонны к обработке блокировок как и я, куча вызовов метода <strong>join</strong>. А впоследствии будет еще сложнее!</p>

<p>А что было сделано? Да практически ничего. Вышеприведенный код представляет собой хрупкую конструкцию. Это внимательное следование шаблону, это высокая вероятность ошибок (я даже забыл вызвать метод <em>task_done()</em> в объекте очереди пока писал это), и это много делать и мало получить. К счастью, есть гораздо лучший способ.</p>

<h2>Знакомьтесь: <strong>Map</strong></h2>

<p><em>Map</em> &ndash; это класная маленькая функция, а главное, проста для распараллеливания вашего Python кода. Для тех, кто не вкурсе, <em>map</em> заимствована из функциональных языков, вроде Lisp'а. Это функция, которая применяет другую функцию к последовательности, например:</p>

<p><code>python
urls = ['http://www.yahoo.com', 'http://www.reddit.com']
results = map(urllib2.urlopen, urls)
</code></p>

<p>Этот код применяет метод <em>urlopen</em> к каждому элементу переданной последовательности и сохраняет полученные результаты в список. Это более-менее эквивалентно следующему коду:</p>

<p>``` python
results = []
for url in urls:</p>

<pre><code>results.append(urllib2.urlopen(url))
</code></pre>

<p>```</p>

<p> Функция <em>map</em> управляет итерацией последовательности, применяет нужную функцию, и в конце сохраняет все получившиеся результаты в список.</p>

<p> Почему это имеет значение? Потому, что используя определенные библиотеки, <em>map</em> делает использование многопоточности тривиальным!</p>

<p> Функция <em>map</em> с поддержкой многопоточности присутствует в двух библиотеках: <strong>multiprocessing</strong>, а так же малоизвестная, но неменее замечательная &ndash; <strong>multiprocessing.dummy</strong>.</p>

<p><em>Отступление:</em> Что это? Никогда не слышал о многопоточном клоне библиотеки <strong>multiprocessing</strong> под названием <em>dummy</em>? Я тоже не слышал до недавнего времени. Есть всего одно предлоение на странице официальной документации библиотеки <strong>multiprocessing</strong>. И это предложение сводится к &ldquo;Ах да, эта вещь существует&rdquo;. Это печально, скажуя вам!</p>

<p><strong>multiprocessing.dummy</strong> представляет собой точный аналог модуля <strong>multiprocessing</strong>. Разница лишь в том, что <strong>multiprocessing</strong> работает с процессами, а <strong>multiprocessing.dummy</strong> использует треды (со всеми присущими им ограничениями). Поэтому, все что относится к одной библиотеке, относится и к другой. Это делает переключение между ними довольно простым.</p>

<h2>Приступим</h2>

<p>Для доступа к map-параллельной функции, сперва нужно импортировать модули в которых она содержится и создать пулл:</p>

<p>``` python
from multiprocessing import Pool
from multiprocessing.dummy import Pool as ThreadPool</p>

<p>pool = ThreadPool()
```</p>

<p>Последнее выражение делает то же, что и семистрочная функция <em>build_worker_pool</em> в приведенном ранее примере. А именно, создает кучу доступных воркеров, поготавливает их к выполнению задач, и сохраняет их в переменной, что бы к ним было легко обратиться.</p>

<p>Объекты из пула принимают несколько параметров, но сейчас упоминания стоит только один: <em>processes</em>. Этот параметр устанавливает количество воркеров в пуле. Если оставить это поле пустым, то по умолчанию оно будет равно количеству ядер в вашем процессоре.</p>

<p>В общем случае, если вы используете многопроцессовый пулл для ядро-раздельных задач, то больше ядер означает большуую скорость (я говорю это с многочисленными оговорками). Однако, когда речь идет о многопоточной обработке и делах связанных с сетью, это не так, и будет хорошей идеей поэксперементировать с размером пула.</p>

<p><code>python
pool = ThreadPool(4) # Sets the pool size to 4
</code></p>

<p>Если вы запустите слишком много потоков, вы затратите больше времени на переключения между ними, чем на полезную работу, так что в этом случае неплох поизменять параметры до тех пор, пока не найдет оптимальный вариант для вашей задачи.</p>

<p>Итак, теперь, когда созданы воркеры и простой способ распараллеливания в наших руках, давайте перепишем загрузку веб-страниц из предыдущего примера.</p>

<p>``` python
import urllib2
from multiprocessing.dummy import Pool as ThreadPool</p>

<p>urls = [</p>

<pre><code>'http://www.python.org', 
'http://www.python.org/about/',
'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html',
'http://www.python.org/doc/',
'http://www.python.org/download/',
'http://www.python.org/getit/',
'http://www.python.org/community/',
'https://wiki.python.org/moin/',
'http://planet.python.org/',
'https://wiki.python.org/moin/LocalUserGroups',
'http://www.python.org/psf/',
'http://docs.python.org/devguide/',
'http://www.python.org/community/awards/'
# etc.. 
]
</code></pre>

<h1>Make the Pool of workers</h1>

<p>pool = ThreadPool(4)</p>

<h1>Open the urls in their own threads</h1>

<h1>and return the results</h1>

<p>results = pool.map(urllib2.urlopen, urls)</p>

<h1>close the pool and wait for the work to finish</h1>

<p>pool.close()
pool.join()
```</p>

<p>Посмотрите на это! Код который на самом деле работает занимает 4 строки, 3 из которых формальны. Функция <strong>map</strong> сделала то же, что и предыдущий код в 40 строк с такой легкостью! Для проверки я испробовал оба подхода и попробовал различные размеры пула.</p>

<p>``` python
results = []
for url in urls:</p>

<pre><code>result = urllib2.urlopen(url)
results.append(result)
</code></pre>

<h1>&mdash;&mdash;&mdash;&ndash; VERSUS &mdash;&mdash;&mdash;&ndash; #</h1>

<h1>&mdash;&mdash;&mdash;&ndash; 4 Pool &mdash;&mdash;&mdash;&ndash; #</h1>

<p>pool = ThreadPool(4)
results = pool.map(urllib2.urlopen, urls)</p>

<h1>&mdash;&mdash;&mdash;&ndash; 8 Pool &mdash;&mdash;&mdash;&ndash; #</h1>

<p>pool = ThreadPool(8)
results = pool.map(urllib2.urlopen, urls)</p>

<h1>&mdash;&mdash;&mdash;&ndash; 13 Pool &mdash;&mdash;&mdash;&ndash; #</h1>

<p>pool = ThreadPool(13)
results = pool.map(urllib2.urlopen, urls)
```</p>

<h2>Результаты:</h2>

<p>```</p>

<pre><code>                    Single thread:  14.4 Seconds 
                           4 Pool:   3.1 Seconds
                           8 Pool:   1.4 Seconds
                          13 Pool:   1.3 Seconds
</code></pre>

<p>```</p>

<p>Потрясающе! Это так же показывает, почему полезно поэкспериментировать с размером пула. Любой пулл с более чем 9 воркерами быстро приводит в падению прироста скорости (на этом компе).</p>

<h1>Реальный пример №2</h1>

<p>Создание миниатюр для тысяч изображений</p>

<p>Теперь давайте сделаем что-нибудь процесорно-раздельное! Довольно распространенная задача у меня на работе &ndash; это обработка больших коллекций картинок. Одна из таких задач &ndash; создание миниатюр. И это можно распараллелить.</p>

<h2>Простая однопроцессная реализация</h2>

<p>``` python
import os
from PIL import Image</p>

<p>SIZE = (75, 75)
SAVE_DIRECTORY = &lsquo;thumbs&rsquo;</p>

<p>def get_image_paths(folder):</p>

<pre><code>return (os.path.join(folder, f)
        for f in os.listdir(folder)
        if 'jpeg' in f)
</code></pre>

<p>def create_thumbnail(filename):</p>

<pre><code>im = Image.open(filename)
im.thumbnail(SIZE, Image.ANTIALIAS)
base, fname = os.path.split(filename)
save_path = os.path.join(base, SAVE_DIRECTORY, fname)
im.save(save_path)
</code></pre>

<p>if <strong>name</strong> == &lsquo;<strong>main</strong>&rsquo;:</p>

<pre><code>folder = os.path.abspath('images_path')
os.mkdir(os.path.join(folder, SAVE_DIRECTORY))

images = get_image_paths(folder)

for image in images:
    create_thumbnail(image)
</code></pre>

<p>```</p>

<p>Пример несколько адаптирован, но по сути происходит следующее: каталог с изображениями передается в программу, потом из каталога выбираются все картинки, и наконец создаются миниатюры и сохраняются в отдельный каталог.</p>

<p>На моем компьютере это выполняется за 27.9 секунд для порядка 6000 изображений.</p>

<p>Если мы заменим цикл <strong>for</strong> параллельной функцией <strong>map</strong>:</p>

<p>``` python
import os
from PIL import Image
from multiprocessing import Pool</p>

<p>SIZE = (75, 75)
SAVE_DIRECTORY = &lsquo;thumbs&rsquo;</p>

<p>def get_image_paths(folder):</p>

<pre><code>return (os.path.join(folder, f)
        for f in os.listdir(folder)
        if 'jpeg' in f)
</code></pre>

<p>def create_thumbnail(filename):</p>

<pre><code>im = Image.open(filename)
im.thumbnail(SIZE, Image.ANTIALIAS)
base, fname = os.path.split(filename)
save_path = os.path.join(base, SAVE_DIRECTORY, fname)
im.save(save_path)
</code></pre>

<p>if <strong>name</strong> == &lsquo;<strong>main</strong>&rsquo;:</p>

<pre><code>folder = os.path.abspath('images_path')
os.mkdir(os.path.join(folder, SAVE_DIRECTORY))

images = get_image_paths(folder)

pool = Pool()
pool.map(create_thumbnail, images)
pool.close()
pool.join()
</code></pre>

<p>```</p>

<p><strong>5.6 секунд!</strong></p>

<p>Это серъезный прирост для изменения всего лишь нескольких строчек кода. Продакшен версия еще быстрее, так как в ней разделены процессорные задачи и задачи ввода-вывода на отдельные процессы и потоки &ndash; обычный рецепт для кода с учетом блокировок.</p>

<p>Так что, так. Распараллеливание в одну (почти) строку.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Начиная Python-проект: The Right Way]]></title>
    <link href="http://toly.github.io/blog/2014/02/09/starting-a-python-project-the-right-way/"/>
    <updated>2014-02-09T21:33:26+04:00</updated>
    <id>http://toly.github.io/blog/2014/02/09/starting-a-python-project-the-right-way</id>
    <content type="html"><![CDATA[<blockquote><p>Достаточно вольный (настолько вольный, что отсутствуют два абзаца и изменен код) перевод статьи Джефа Кнаппа</p>

<p><a href="http://www.jeffknupp.com/blog/2014/02/04/starting-a-python-project-the-right-way/">Starting A Python Project The Right Way</a></p></blockquote>

<p>Если вы подобны большинству начинающих python-программистов, вы вероятно в состоянии представить себе работу приложения целиком, но когда приходит время начать писать код и перед вами пустое окно редактора, вы чувствуете себя потерянным и подавленным. В этой статье я опишу метод, который использую когда начинаю писать программу с нуля. К концу статьи у вас будет хороший план для начала разработки любого приложения.</p>

<!-- more -->


<h2>Установка</h2>

<p>До того как написать хоть строчку кода, первое что я делаю &ndash; создаю <em>виртуальное окружение</em>. Что такое виртуальное окружение? Это установка python отдельно от остальной части системы (и дефолтного pythona'а). Какая от этого польза? Представьте себе, что у вас есть два проекта, над которыми вы работаете. Если оба испольузют какую-либо библиотеку (например, <strong>requests</strong>), и в одном из проектов используется старая версия (которую нельзя корректно обновить, т.к. другие библиотеки используют старую версию <strong>requests</strong>), как вы сможете использовать новую версию <strong>requests</strong> в другом проекте? С помощью виртуального окружения.</p>

<p>Для начала установите <strong>virtualenvwrapper</strong> (обертка над фантастическим пакетом <strong>virtualenv</strong>). Добавьте в ваш <strong>.bashrc</strong> строчку <code>/usr/local/bin/virtualenvwrapper.sh</code> и перезагрузите свой профиль с помощью <strong>source</strong>:</p>

<pre><code>source ~/.bashrc
</code></pre>

<p>Теперь у вас должна появиться команда <strong>mkvirtualenv</strong>, доступная через автодополнение с помощью <em>tab</em>. Если вы используете Python старше версии 3.3, виртуальное окружение поддерживает этот язык и установка этого пакета не требуется. <code>mkvirtualenv &lt;my_project&gt;</code> создаст новое виртуальное окружение под названием my_project с уже установленными <strong>pip</strong> и <strong>setuptools</strong>. Для Python 3 требуемые команды выглядят так:</p>

<pre><code>python -m venv &lt;my_project&gt;
source &lt;my_project&gt;/bin/activate
</code></pre>

<p>Теперь когда виртуальное окружение создано, пришло время инициализировать средство управления исходниками. Предполагая что это <strong>git</strong> (ну, потому что он&hellip;), введем</p>

<pre><code>git init .
</code></pre>

<p>Так же полезно добавить в <strong>.gitignore</strong> все скомпилированые Python-ом файлы и каталоги <code>__pychache__</code>. Для этого создайте файл <code>.gitignore</code> и поместите в него следующее:</p>

<pre><code>*.pyc
__pycache__
</code></pre>

<p>Теперь подходящее время добавить в проект <strong>README</strong> файл. Даже если вы единственный, кто будет видеть код, это хорошее упражнение для организации ваших мыслей. <strong>README</strong> файл должен описывать что делает проект, его зависимости и как его использовать. Я пишу <strong>README</strong> файлы с использованием разметки <em>Markdown</em>, во-первых потому что GitHub автоматически оформляет любой файл названный <strong>README.md</strong>, а во-вторых потому что я пишу все (!) документы в разметке <em>Markdown</em>.</p>

<p>И наконец, сделайте первый коммит содержащий два файла (<strong>.gitignore</strong>, <strong>README.md</strong>), которые вы только что создали. Для этого введите:</p>

<pre><code>git add .gitignore README.md
git commit -m "initial commit"
</code></pre>

<h2>Каркасы!</h2>

<p>Почти каждое приложение я начинаю одинаково: создаю каркас приложения, состоящий из функций и классов с заполненой документацией, но без реализации. Я считаю, что необходимо сперва вынужденно писать документацию для функции, иначе если я не способен кратко описать что-либо, то у меня нет достаточно мыслей о проблеме.</p>

<p>В качестве примера приложения я использую скрипт, недавно написанный обучаемым во время одного из наших занятий. Цель скрипта &ndash; создать csv-файл, содержащий самые кассовые фильмы прошлого года (по версии IMDB) и ключевые слова связанные с этими фильмами на IMDB. Это был довольно простой проект, для того что бы завершить его за одно занятие, но достаточный по сложности, что бы требовать размышлений.</p>

<p>Сперва создайте основной файл, который будет точкой входа в приложение. Я назвал его <strong>imdb.py</strong>. Потом скопируйте следующий код в редактор:</p>

<p>``` python</p>

<pre><code>""Script to gather IMDB keywords from 2013's top grossing movies."""
import sys

def main():
    """Main entry point for the script."""
    pass

if __name__ == '__main__':
    sys.exit(main())
</code></pre>

<p>```</p>

<p>Звучит неправдоподобно, но это вполне функциональная программа. Вы можете запустить ее и получить правильный код выхода (т.е. <strong>0</strong>, хотя справедливо отметить, что пустой файл будет так же возвращать правильный код). Затем я делаю заглушки для функций и/или классов, которые по моему мнению будут нужны:</p>

<p>``` python</p>

<pre><code>"""Script to gather IMDB keywords from 2013's top grossing movies."""
import sys

URL = "http://www.imdb.com/search/title?at=0&amp;sort=boxoffice_gross_us,desc&amp;start=1&amp;year=2013,2013"

def main():
    """Main entry point for the script."""
    pass

def get_top_grossing_movie_links(url):
    """Return a list of tuples containing the top grossing movies of 2013 and link to their IMDB
    page."""
    pass

def get_keywords_for_movie(url):
    """Return a list of keywords associated with *movie*."""
    pass

if __name__ == '__main__':
    sys.exit(main())
</code></pre>

<p>```</p>

<p>Выглядит сносно. Отмечу, что обе функции включают параметры (например, <strong>get_keywords_for_movie</strong> принимает параметр <strong>url</strong>). Это может показаться странным для заглушек. Зачем здесь параметры? Аргументация такая же, как и для предварительного документирования заглушек: если я не знаю какие агрументы должна принимать функция, значит я недостаточно об этом думал.</p>

<p>В этом месте я верятно закомичусь, т.к. проделал определенную часть работы, которую не хотел бы потерять. После этого перейдем к реализации. Я всегда начинаю с реализации функции <strong>main</strong>, т.к. &ldquo;центр&rdquo; использующий все остальные функции. Вот реализация функции <strong>main</strong> в <strong>imdb.py</strong>:</p>

<p>``` python</p>

<pre><code>import csv

def main():
    """Main entry point for the script."""
    movies = get_top_grossing_movie_links(URL)
    with open('output.csv', 'w') as output:
        csvwriter = csv.writer(output)
        for title, url in movies:
            keywords = get_keywords_for_movie(
                'http://www.imdb.com{}keywords/'.format(url))
            csvwriter.writerow([title, keywords])
</code></pre>

<p>```</p>

<p>Несмотря на то что <strong>get_top_grossing_movie_links</strong> и <strong>get_keywords_for_movie</strong> не реализованы, я знаю достаточно о том, как их использовать. Функция <strong>main</strong> делает именно то, что мы обсуждали вначале: получает самые кассовые фильмы года и пишет их в csv-файл вместе с их ключевыми словами.</p>

<p>Теперь все что осталось, это реализовать недостающие функции. Любопытно, что даже если мы знаем, что <strong>get_keywords_for_movie</strong> будет вызван после <strong>get_top_grossing_movie_links</strong>, мы можем реализовать их в том порядке, который больше нравится. Это не тот случай, когда пишешь скрипт с нуля и добавляешь функционал в том порядке, в которм идет разработка. Вы были бы вынуждены полностью написать первую функцию, прежде чем перети ко второй. Тот факт, что мы можем реализовать (и проверить!) функции в любом порядкепоказывает, что они слабо связаны.</p>

<p>Давайте первым реализуем функцию <strong>get_keywords_for_movie</strong>:</p>

<p>``` python
def get_keywords_for_movie(url):</p>

<pre><code>"""Return a list of keywords associated with *movie*."""
keywords = []
response = requests.get(url)
soup = BeautifulSoup(response.text)
tables = soup.find_all('table', class_='dataTable')
table = tables[0]
return [td.text for tr in table.find_all('tr') for td in tr.find_all('td')]
</code></pre>

<p>```</p>

<p>Мы используем библиотеки <strong>requests</strong> и <strong>BeautifulSoup</strong>, поэтому нам нужно установить их через <em>pip</em>.  Теперь можно внести в список зависимостей проекта новые библиотеки: <code>pip freeze requirements.txt</code> и закомитить изменения. Таким образом мы всегда сможем создать виртуальное окружение и установить именно те библиотеки (и версии) которые нужны для запуска приложения.</p>

<p>Наконец напишем реализацию для функции <strong>get_top_grossing_movie_links</strong>:</p>

<p>``` python
def get_top_grossing_movie_links(url):</p>

<pre><code>"""Return a list of tuples containing the top grossing movies of 2013 and link to their IMDB
page."""
response = requests.get(url)
movies_list = []
for each_url in BeautifulSoup(response.text).select('.title a[href*="title"]'):
    movie_title = each_url.text 
    movies_list.append((movie_title, each_url['href']))
return movies_list
</code></pre>

<p>```</p>

<p>Вот финальное содержание <strong>imdb.py</strong>:</p>

<p>``` python
&ldquo;"Script to gather IMDB keywords from 2013&rsquo;s top grossing movies.&rdquo;&ldquo;&rdquo;
import sys
import requests
from bs4 import BeautifulSoup
import csv</p>

<p>URL = &ldquo;<a href="http://www.imdb.com/search/title?at=0&amp;sort=boxoffice_gross_us,desc&amp;start=1&amp;year=2013,2013">http://www.imdb.com/search/title?at=0&amp;sort=boxoffice_gross_us,desc&amp;start=1&amp;year=2013,2013</a>&rdquo;</p>

<p>def get_top_grossing_movie_links(url):</p>

<pre><code>"""Return a list of tuples containing the top grossing movies of 2013 and link to their IMDB
page."""
response = requests.get(url)
movies_list = []
for each_url in BeautifulSoup(response.text).select('.title a[href*="title"]'):
    movie_title = each_url.text 
    movies_list.append((movie_title, each_url['href']))
return movies_list
</code></pre>

<p>def get_keywords_for_movie(url):</p>

<pre><code>"""Return a list of keywords associated with *movie*."""
keywords = []
response = requests.get(url)
soup = BeautifulSoup(response.text)
tables = soup.find_all('table', class_='dataTable')
table = tables[0]
return [td.text for tr in table.find_all('tr') for td in tr.find_all('td')]
</code></pre>

<p>def main():</p>

<pre><code>"""Main entry point for the script."""
movies = get_top_grossing_movie_links(URL)
with open('output.csv', 'w') as output:
    csvwriter = csv.writer(output)
    for title, url in movies:
        keywords = get_keywords_for_movie('http://www.imdb.com{}keywords/'.format(url))
        csvwriter.writerow([title, keywords])
</code></pre>

<p>if <strong>name</strong> == &lsquo;<strong>main</strong>&rsquo;:</p>

<pre><code>sys.exit(main())
</code></pre>

<p>```</p>

<p>Приложение, которое начиналось с пустого окна редактора готово. После запуска скрипт сгенерирует <strong>output.csv</strong>, содержащий именно то, что нужно. Для скрипта такого размера я не стал бы писать тесты, т.к. результат работы программы и есть тест. Тем не менее, написание тестов в данном случае возможно (так как наши функции слабо связаны), что бы проверить каждую функцию отдельно (изолированно).</p>

<h2>Заключение</h2>

<p>Надеюсь теперь у вас есть план действий для начала работы над python-проектом с нуля. Не смотря на то, что у каждого есть свой метод начала работы над проектом, скорее всего мой метод подойдет и вам. Как всегда, если у вас есть какие-либо вопросы, не стесняйтесь задавать их в комментариях или напишите мне на <a href="&#x6d;&#97;&#105;&#x6c;&#x74;&#111;&#58;&#106;&#x65;&#x66;&#x66;&#64;&#106;&#x65;&#x66;&#x66;&#107;&#x6e;&#117;&#x70;&#x70;&#46;&#x63;&#111;&#x6d;&#46;">&#x6a;&#101;&#102;&#x66;&#x40;&#106;&#x65;&#x66;&#x66;&#107;&#110;&#117;&#x70;&#x70;&#x2e;&#99;&#x6f;&#x6d;&#46;</a></p>
]]></content>
  </entry>
  
</feed>
